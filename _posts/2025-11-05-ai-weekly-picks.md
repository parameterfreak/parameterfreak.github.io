---
title: 'AI Weekly Picks(20251105)'
date: 2025-11-05
permalink: /posts/2025/11/ai-weekly-picks-2025-11-05/
categories:
  - Misc
tags:
  - AI
  - News
---

# AI Weekly Picks(20251105)

# Simplified and Secure MCP Gateways for Enterprise AI Integration

- [https://arxiv.org/pdf/2504.19997](https://arxiv.org/pdf/2504.19997)
- 모델 컨텍스트 프로토콜(MCP) 게이트웨이라는 전용 중개자 아키텍처를 제안하며, 이는 기업 AI 통합 시 보안 문제를 간소화하는 데 중점을 둡니다. 이 연구는 기업이 자체 호스팅하는 AI 환경의 독특한 보안 요구 사항을 해결하기 위해 인증, 침입 탐지 및 제로 트러스트 터널링을 중앙 집중화합니다. 게이트웨이는 OAuth 2.1 준수를 추상화하여 백엔드 MCP 서버가 도구 실행에만 집중할 수 있도록 하며, 이는 MAESTRO 및 다른 보안 프레임워크에 대한 매핑을 통해 검증됩니다. 또한, 개념 증명(PoC) 구현은 Traefik 및 WireGuard와 같은 오픈 소스 구성 요소를 사용하여 이 아키텍처의 실현 가능성과 보안 이점을 입증합니다.

# Benchmarking Document Parsing (and What Actually Matters)

- [https://unstructured.io/blog/benchmarking-document-parsing-and-what-actually-matters](https://unstructured.io/blog/benchmarking-document-parsing-and-what-actually-matters)
- 문서 구문 분석 시스템을 평가하는 기존 방식의 한계를 다루며, **Unstructured**가 개발한 새로운 평가 프레임워크인 **SCORE**에 대해 설명하고 있습니다. 전통적인 측정 기준은 구조적으로 다를 수 있는 의미론적으로 정확한 출력을 부당하게 **불이익**을 주는 경향이 있으며, 이로 인해 시스템 성능에 대한 **오해**를 불러일으킬 수 있습니다. SCORE 프레임워크는 이러한 문제를 해결하기 위해 **해석에 구애받지 않는** 접근 방식을 취하며, 콘텐츠 충실도, 환각 제어, 구조적 이해 등 **다차원적인 지표**를 사용하여 실제 엔터프라이즈 데이터에 대한 시스템 성능을 평가합니다. 궁극적으로 이 문서는 벤치마크 점수보다는 **다운스트림 애플리케이션 성공**과 상관관계가 있는 평가의 필요성을 강조합니다.

# Lookahead Routing for Large Language Models

- [https://arxiv.org/abs/2510.19506](https://arxiv.org/abs/2510.19506)
- **대규모 언어 모델(LLM) 라우팅의 효율성과 정확도를 향상시키기 위한 새로운 프레임워크인 Lookahead**를 소개하는 연구 논문
- 기존 라우팅 방식은 오직 입력 쿼리에만 의존하여 모델을 선택함으로써 잠재적인 출력 정보를 무시하는 한계를 가집니다. Lookahead는 **전체 응답을 생성하는 계산 비용 없이** 각 후보 모델의 **잠재 응답 표현을 예측**하고, 이 예측을 사용하여 모델 선택을 안내합니다. 이 논문은 인과 언어 모델(CLM)과 마스크 언어 모델(MLM)을 기반으로 두 가지 Lookahead 구현 방식을 제시하며, 7가지 벤치마크에서 기존 최첨단 라우팅 방법론 대비 **평균 7.7%의 성능 향상**을 달성했음을 입증합니다. 이러한 **응답 인지(response-aware) 라우팅** 접근 방식은 특히 복잡하거나 모호한 쿼리에 대해 더 정확하고 상황에 맞는 결정을 가능하게 합니다.

# How to Read a Paper

- [https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf](https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf)
- **1단계 (First Pass):** 논문에 대한 **일반적인 아이디어**를 파악합니다
    - 소요 시간은 약 **5분에서 10분**입니다
    - 이 단계 후 독자는 논문을 더 읽을지 여부를 결정할 수 있습니다
    - 논문이 자신의 연구 분야가 아니지만 언젠가 관련이 있을 수 있는 논문이라면 이 단계만으로도 충분합니다
    - 진행 방법
        - **제목, 초록, 서론**을 주의 깊게 읽습니다.
        - 다른 모든 것을 무시하고 **섹션 및 하위 섹션 제목**을 읽습니다.
        - **결론**을 읽습니다.
        - 이미 읽은 참고 문헌을 마음속으로 확인하며 **참고 문헌**을 훑어봅니다.
- **2단계 (Second Pass):** 논문의 **내용**을 파악하지만, 증명과 같은 세부 사항은 무시합니다
    - 소요 시간은 약 **한 시간**까지 걸릴 수 있습니다
    - 이 단계 후에는 논문의 주요 내용을 보조 증거와 함께 다른 사람에게 요약해 줄 수 있어야 합니다. 이는 관심은 있지만 자신의 연구 전문 분야가 아닌 논문에 적합한 깊이입니다
        - 두 번째 단계를 마친 후에도 논문을 이해하지 못하는 경우가 있을 수 있습니다. 이는 주제가 낯설거나, 저자가 이해할 수 없는 증명이나 실험 기법을 사용했거나, 논문이 제대로 작성되지 않았거나(입증되지 않은 주장, 수많은 전방 참조), 단순히 피곤하기 때문일 수 있습니다. 이 경우 독자는 (a) 논문을 치워두거나, (b) 배경 자료를 읽은 후 나중에 돌아오거나, (c) 인내심을 갖고 **세 번째 단계(third pass)로 넘어갈** 수 있습니다.
    - 진행 방법
        - **핵심 기록:** 읽으면서 **핵심 요점을 적어** 놓거나 **여백에 주석**을 다는 것이 도움이 됩니다
        - **시각 자료 주의:** 논문에 있는 **그림, 다이어그램, 기타 삽화**를 주의 깊게 살펴봅니다
        - **그래프 검토:** 특히 **그래프**에 주의를 기울여 축에 라벨이 제대로 붙어 있는지, 결론이 통계적으로 유의미하도록 **오차 막대(error bars)**와 함께 결과가 표시되는지 확인합니다. 이러한 흔한 실수는 서두르고 조잡한 작업과 진정으로 훌륭한 작업을 구분하는 기준이 될 수 있습니다
        - **참고 문헌 표시:** 추가 독서를 위해 아직 읽지 않은 **관련 참고 문헌**을 표시해 둡니다. 이는 논문의 배경 지식을 더 배우는 좋은 방법입니다
- **3단계 (Third Pass):** 논문을 **심층적으로 이해**하는 데 도움을 줍니다
    - 이 단계는 논문을 가상으로 재구현(virtually re-implement)해 보려는 시도를 핵심으로 하며, 저자와 동일한 가정을 합니다
    - 초보자는 약 **4~5시간**, 숙련된 독자는 약 **한 시간**이 소요될 수 있습니다
    - 이 단계를 통해 논문의 혁신뿐만 아니라 숨겨진 결함과 가정을 식별할 수 있으며, 논문의 강점과 약점을 정확히 파악할 수 있게 됩니다. 특히 **검토자**라면 이 단계가 필요합니다
    - 진행 방법
        - **가상 재구현 시도:** 저자와 **동일한 가정**을 하면서 논문의 작업을 **재구현**하려고 시도해야 합니다. 이 과정을 통해 논문의 혁신뿐만 아니라 **숨겨진 결함과 가정**을 쉽게 식별할 수 있습니다.
        - **가정에 이의 제기:** **모든 진술에 있는 모든 가정에 이의를 제기하고 도전**해야 합니다
        - **발표 기법 비교 및 습득:** 저자가 특정 아이디어를 어떻게 제시했는지와 독자 자신이 어떻게 제시했을지 비교하여 논문의 **증명 및 발표 기법에 대한 통찰력**을 얻고 이를 자신의 **도구 레퍼토리**로 추가할 수 있습니다
        - **아이디어 기록:** 이 과정에서 **향후 작업(future work)에 대한 아이디어를 기록**해야 합니다