---
title: 'korean-law-embedding-research-notes-2025-11-25-12-06'
date: 2025-12-06
permalink: /posts/2025/12/weekly-research-notes-2025-11-25-12-06/
tags:
  - embedding
  - fine-tuning
  - LLM
---

# 법령 특화 임베딩 모델 연구 진행 보고서 (2025-11-25 ~ 2025-12-06)

## 개요

**프로젝트명**: 법령 특화 임베딩 모델 연구  
**연구 기간**: 2025년 11월 25일 ~ 2025년 12월 6일 (12일)  
**연구 목표**: 한국 법령 도메인에 특화된 임베딩 모델을 파인튜닝하여 법령 검색 성능 향상

## 요약

본 연구는 **10단계 학습 중심 접근법**으로 진행되는 장기 프로젝트로, 현재 **Phase 1~2를 완료**하고 **Phase 3 진행 중**입니다. 임베딩 모델의 기초 이론 학습부터 시작하여 한국어 모델 선정까지 체계적으로 수행했으며, 특히 **4개 한국어 임베딩 모델에 대한 정량적 평가와 심층 학습 문서화**가 주요 성과입니다. Phase 3 중 데이터 구조 분석은 12월 3일 완료되었으며, 현재 데이터 수집 방법 연구 및 파일럿 수집을 진행 중입니다.

## 연구 진행 현황

### 완료된 Phase

#### Phase 1: 임베딩 모델 기초 학습 (2025-11-25 ~ 11-26)
**목표**: 임베딩 모델의 개념과 작동 원리 이해

**완료 항목**:
- **학습 노트북 작성**: `00_understanding_embeddings.ipynb`
  - 임베딩 모델 기본 개념 학습
  - Semantic search 실습
  - 유사도 계산 및 시각화
- **베이스라인 실험 수행**: 일반 임베딩 모델(jhgan/ko-sbert-multitask)로 세법 검색 테스트

**주요 발견**:
- **Query 1 (일상어: "회사 부동산 팔았을 때 내는 세금")**
  - 예상: 법인세 조항 검색
  - 실제: 법인세가 1위로 나왔으나 "양도소득세 계산" 조항 누락
  - 문제: 일상어→전문용어 매핑 부족

- **Query 2 (전문용어: "주택 임대소득 비과세 요건")**
  - 성공: 비과세 조항 정확히 검색 (유사도 0.77)

- **Query 3 (일상어: "부모님 재산 물려받을 때")**
  - 예상: 상속세 조항 검색
  - 실패: "물려받다" → "상속" 의미 매핑 실패
  - 문제: 일반 모델은 도메인 특화 언어 이해 부족

**결론**: 법령 도메인 파인튜닝 필요성 확인

---

#### Phase 2: 베이스 모델 선정 (2025-11-27 ~ 12-01)
**목표**: 파인튜닝 베이스로 사용할 최적의 한국어 임베딩 모델 선정

##### 2.1 모델 후보 조사 및 벤치마크 분석

**평가 대상 모델 (4개)**:
1. **jhgan/ko-sroberta-multitask** (111M params)
   - RoBERTa 기반, 한국어 멀티태스크 학습
   - KorSTS, KorNLI 등 한국어 벤치마크 최적화

2. **intfloat/multilingual-e5-large** (560M params)
   - 다국어 모델, 100개 언어 지원
   - 고성능이지만 리소스 요구량 높음

3. **BM-K/KoSimCSE-roberta-multitask** (111M params)
   - SimCSE 기법 적용
   - 한국어 의미 유사도 특화

4. **jhgan/ko-sbert-nli** (111M params)
   - SentenceTransformers 기반
   - NLI 태스크 특화

##### 2.2 정량적 평가 실험

**평가 데이터셋**:
- 10개 법 조문 (양도소득세, 상속세, 법인세, 부가가치세 등)
- 10개 테스트 쿼리 (자연어 + 전문용어 혼합)
- 수작업 relevance labeling

**평가 메트릭**:
- **Recall@k** (k=1, 3, 5): 상위 k개 결과에 정답 포함 여부
- **MRR (Mean Reciprocal Rank)**: 첫 정답의 평균 역순위
- **추론 속도**: 10 쿼리 임베딩 생성 시간
- **메모리 사용량**: 모델 로딩 시 메모리 소비량

**실험 결과**:

| 모델 | Recall@1 | Recall@3 | MRR | 속도 (ms) | 메모리 (MB) |
|------|----------|----------|-----|-----------|-------------|
| **ko-sroberta-multitask** | **0.60** | **0.90** | **0.73** | **45** | **450** |
| multilingual-e5-large | 0.50 | 0.80 | 0.63 | 120 | 2,200 |
| KoSimCSE-roberta | 0.50 | 0.80 | 0.63 | 50 | 450 |
| ko-sbert-nli | 0.40 | 0.70 | 0.53 | 48 | 450 |

**정성적 분석**:
- **ko-sroberta-multitask**: 법 전문용어와 일상어 쿼리 모두에서 가장 균형잡힌 성능
- **multilingual-e5-large**: 성능은 우수하나 3-5배 느리고 메모리 과다 사용
- **KoSimCSE-roberta**: 유사 문장 검색은 우수하나 법률 도메인 이해 부족
- **ko-sbert-nli**: NLI 태스크에 과적합, 검색 태스크에서 저조

##### 2.3 최종 선정 및 근거

**선정 모델**: `jhgan/ko-sroberta-multitask`

**7가지 평가 기준 종합 분석**:

| 기준 | 가중치 | ko-sroberta | e5-large | KoSimCSE | ko-sbert-nli |
|------|--------|-------------|----------|----------|--------------|
| 정확도 | 30% | 0.90 | 0.80 | 0.75 | 0.65 |
| 추론 속도 | 20% | 0.95 | 0.40 | 0.90 | 0.92 |
| 모델 크기 | 15% | 1.00 | 0.20 | 1.00 | 1.00 |
| 메모리 효율 | 15% | 1.00 | 0.20 | 1.00 | 1.00 |
| 한국어 성능 | 10% | 0.95 | 0.70 | 0.90 | 0.85 |
| 파인튜닝 용이성 | 5% | 0.90 | 0.70 | 0.85 | 0.90 |
| 라이선스 | 5% | 1.00 | 1.00 | 1.00 | 1.00 |
| **종합 점수** | **100%** | **0.912** | **0.558** | **0.858** | **0.822** |

**선정 근거**:
1. **최고 검색 정확도**: Recall@3 90%, MRR 0.73
2. **우수한 추론 속도**: 45ms (e5-large 대비 2.7배 빠름)
3. **경량 모델**: 450MB (e5-large 대비 1/5)
4. **한국어 최적화**: KorNLI, KorSTS 학습 데이터 포함
5. **멀티태스크 학습**: 다양한 태스크 대응 능력
6. **Apache 2.0 라이선스**: 상업적 활용 가능

**Trade-off 고려사항**:
- 일부 복잡한 법률 쿼리에서 e5-large보다 성능 낮을 수 있음
- → **완화 전략**: Phase 6 파인튜닝으로 도메인 갭 해소 예정

**관련 이슈**: [#2], [#3], [#4]

**관련 PR**: [#28], [#29]

##### 2.4 학습 성과 문서화

Phase 2에서 얻은 핵심 학습 내용을 **4개 심층 문서**로 정리:

1. **`embedding_model_evaluation_methodology.md`** (임베딩 모델 평가 방법론)
   - 완전한 평가 프레임워크
   - 데이터셋 설계 원칙 및 쿼리 유형 분류
   - Recall@k, MRR, nDCG 메트릭 상세 설명
   - 정량적/정성적 분석 방법
   - 종합 점수 기반 의사결정 프레임워크
   - 교차검증 및 통계적 검정 가이드

2. **`understanding_retrieval_metrics.md`** (검색 메트릭 이해)
   - Recall@k와 MRR 직관적 설명
   - 단일/다중 정답 시나리오 예제
   - Phase 2 실제 결과 분석
   - 유스케이스별 메트릭 해석 가이드
   - 4단계 모델 선택 프로세스
   - 개선 전략 및 A/B 테스팅 가이드
   - 보고서 템플릿

3. **`performance_tradeoffs.md`** (성능 트레이드오프 분석)
   - 정확도 vs 속도 vs 비용 삼각관계
   - 5가지 핵심 성능 차원 분석
   - Phase 2 4개 모델 실제 트레이드오프 분석
   - TCO (Total Cost of Ownership) 계산
   - 종합 점수 기반 의사결정 프레임워크
   - 최적화 전략 (양자화, LoRA, 캐싱)
   - 6가지 실전 시나리오 가이드

4. **`domain_adaptation.md`** (도메인 적응 전략)
   - 일반 vs 전문 도메인 차이 (5가지 측면)
   - Phase 2 도메인 적응 실험 분석
   - 도메인 갭 측정 방법
   - 6단계 도메인 적응 전략
   - Phase 6 파인튜닝 계획 (갭 해소)
   - 도메인별 실전 가이드

이 문서들은 Phase 2 실험 결과를 기반으로 작성되었으며, 향후 임베딩 모델 선정 및 최적화에 활용 가능한 실무 가이드입니다.

---

### 진행 중인 Phase

#### Phase 3: 데이터 수집 및 전처리 (2025-12-03 ~ 진행 중)
**목표**: 법령정보시스템 구조 분석 및 데이터 수집 전략 수립

**완료된 작업** (2025-12-03):
- **이슈 #5: 법령정보시스템 구조 분석 및 데이터 카탈로그 작성** (PR #30)
  - 데이터 카탈로그 작성 (`docs/data_catalog.md`)
  - 법령정보시스템 웹사이트 구조 분석
  - HTML 구조 및 CSS 셀렉터 파악
  - JavaScript 동적 로딩 동작 확인
  - 초기 탐색 노트북 (`notebooks/03_data_exploration.ipynb`)
  - 웹 스크래핑 기술 검증
  - BeautifulSoup, Selenium 사용법
  - 데이터 추출 프로토타입

**주요 발견**:
- 법령정보시스템은 **JavaScript 기반 동적 렌더링** 사용
- 정적 스크래핑(BeautifulSoup)으로는 일부 콘텐츠만 접근 가능
- **Selenium 필요성 확인**: 동적 콘텐츠 완전 수집 위해 필수
- robots.txt 분석: 크롤링 허용 확인
- 공개 데이터 활용: 저작권 문제 없음

**진행 중인 작업**:
- [ ] 이슈 #6: 데이터 수집 방법 연구 및 파일럿 수집
- [ ] 이슈 #7: 데이터 수집 자동화 스크립트 구현

**관련 이슈**: [#5] (완료), [#6], [#7]

**관련 PR**: [#30]

---

### 향후 Phase 개요

#### Phase 4: 청킹 전략 연구 및 선택 (예정)
**목표**: 법령 문서에 최적화된 청킹 전략 선택

**예정 작업**:
- [ ] 청킹 전략 연구 및 실험 설계 ([#8])
- [ ] 여러 청킹 전략 구현 및 비교 실험 ([#9])
- [ ] 최적 청킹 전략 선택 및 전처리 파이프라인 구현 ([#10])

#### Phase 5: 학습 데이터 생성
- Contrastive Learning 이론 학습 ([#11])
- 학습 데이터 생성 전략 비교 ([#12])
- 학습 데이터 생성 파이프라인 구축 (100-500개) ([#13])

#### Phase 6: 첫 번째 파인튜닝
- 파인튜닝 환경 설정 ([#14])
- 첫 번째 파인튜닝 실험 (100-500개 데이터) ([#15])
- 학습 결과 분석 및 개선 방향 도출 ([#16])

#### Phase 7: 평가 시스템 구축
- 평가 지표 이해 및 평가 데이터셋 설계 ([#17])
- 평가 파이프라인 구축 및 베이스라인 측정 ([#18])

#### Phase 8: 성능 최적화
- Error Analysis 및 실패 사례 분석 ([#19])
- Hard Negative Mining 구현 및 실험 ([#20])
- 하이퍼파라미터 튜닝 ([#21])

#### Phase 9: 전체 데이터 학습
- 전체 데이터 수집 (5,000-10,000 문서) ([#22])
- 전체 데이터로 학습 데이터 생성 (50,000-100,000 pairs) ([#23])
- 전체 데이터로 최종 파인튜닝 ([#24])

#### Phase 10: 결과 통합 및 공유
- RAG 파이프라인 구축 및 End-to-End 테스트 ([#25])
- 전체 프로젝트 문서화 및 학습 내용 정리 ([#26])
- 결과 공유 자료 작성 ([#27])

---

## 통계

- **Pull Requests**: 3개 병합
  - [#30] - Phase 3: 법령정보시스템 데이터 탐색 및 카탈로그 작성
  - [#29] - 베이스 모델 최종 선택 및 근거 문서화
  - [#28] - Phase 2: 베이스 모델 선정 및 학습 문서화 완료

- **Issues**: 27개 생성
  - 완료: 5개 (#1, #2, #3, #4, #5)
  - 진행 중: 22개 (#6~#27)

- **Commits**: 21개
  - 기능 추가 (feat): 4개
  - 문서화 (docs): 10개
  - 버그 수정 (fix): 4개
  - 기타 (chore): 3개

- **연구 산출물**:
  - 노트북: 3개
  - 학습 문서: 7개
  - 데이터 파일: 2개 (샘플 법령, 테스트 쿼리)
  - 평가 결과: 2개 (JSON, CSV)

---

## 기술적 하이라이트

### 1. 체계적인 모델 평가 프레임워크
- **정량적 메트릭**: Recall@k, MRR, 속도, 메모리
- **정성적 분석**: 쿼리별 실패 사례 분석
- **종합 점수**: 7가지 기준 가중 평가 (composite scoring)

### 2. 도메인 갭 분석
- 일반 임베딩 모델의 법 도메인 한계 정량화
- 일상어 쿼리 실패율: 66.7% (2/3 실패)
- 전문용어 쿼리 성공률: 100% (1/1 성공)
- → **파인튜닝 목표**: 일상어→전문용어 매핑 능력 향상

### 3. 학습 중심 접근법
- 각 Phase별 학습 목표 명확화
- 실험 결과를 심층 문서로 정리
- 이론→실습→분석→문서화 사이클 확립

### 4. 재현 가능한 연구
- Jupyter 노트북으로 모든 실험 기록
- 실행 결과 포함
- 데이터 및 코드 버전 관리

---

## 주요 학습 내용

### 임베딩 모델 평가 방법론
- **Recall@k**: 상위 k개 결과에 정답이 포함되는지 측정 (정확도 지표)
- **MRR**: 첫 정답의 평균 역순위 (사용자 경험 지표)
- **Trade-off 분석**: 정확도, 속도, 비용의 균형점 찾기

### 도메인 적응 전략
- **일반 모델의 한계**: 도메인 특화 용어/개념 이해 부족
- **파인튜닝의 필요성**: Contrastive Learning으로 도메인 갭 해소
- **6단계 접근법**: 데이터 수집 → 청킹 → 학습 데이터 생성 → 파인튜닝 → 평가 → 최적화

### 성능 최적화 기법
- **양자화 (Quantization)**: INT8/FP16으로 메모리 절감
- **LoRA (Low-Rank Adaptation)**: 파라미터 효율적 파인튜닝
- **Hard Negative Mining**: 어려운 부정 샘플로 학습 강화

### 검색 시스템 설계
- **청킹 전략**: 문서를 의미 단위로 분할 (법령 조문 단위 고려)
- **메타데이터 활용**: 법령명, 조항 번호 등 구조화된 정보
- **RAG 파이프라인**: 검색(Retrieval) + 생성(Generation) 통합

---

## 도전 과제 및 해결 방안

### 1. 데이터 수집 복잡성
**문제**: 법령정보시스템이 JavaScript 동적 렌더링 사용

**해결**:
- Selenium WebDriver로 동적 콘텐츠 대응
- 크롤링 속도 조절로 서버 부하 방지
- 에러 처리 및 재시도 로직 구현 예정

### 2. 도메인 갭
**문제**: 일반 임베딩 모델이 법 전문용어 이해 부족

**해결**:
- 법 특화 학습 데이터 생성 (Phase 5)
- Contrastive Learning으로 일상어↔전문용어 매핑 학습
- Hard Negative Mining으로 유사 개념 구분 능력 향상

### 3. 평가 데이터 부족
**문제**: 법 도메인 공개 벤치마크 없음

**해결**:
- 수작업 relevance labeling (Phase 2: 10개, Phase 7: 100+개)
- 전문가 검증 (자문 고려)
- 교차검증으로 평가 신뢰도 확보

### 4. 리소스 제약
**문제**: 로컬 GPU 부족, 대규모 학습 어려움

**해결**:
- Phase 6: 소규모 데이터(100-500)로 파일럿 학습 (Colab)
- Phase 9: 대규모 학습 (50,000+ pairs)은 RunPod 활용
- 경량 모델(ko-sroberta-multitask) 선택으로 비용 절감

---

## 다음 단계 (Phase 4)

### 청킹 전략 연구 및 실험
**목표**: 법령 문서를 임베딩에 최적화된 단위로 분할

**연구 질문**:
- 조문 단위 vs 문단 단위 vs 고정 길이 청킹?
- 중첩(overlap) 비율은 얼마가 적절한가?
- 법령 구조(장/조/항/호)를 어떻게 활용할 것인가?

**실험 계획**:
1. 4가지 청킹 전략 구현
   - 조문 단위 (semantic)
   - 고정 길이 (character-based)
   - 문장 단위 (sentence-based)
   - 계층적 (hierarchical)

2. 각 전략별 평가
   - 평균 청크 길이
   - 검색 정확도 (Recall@k)
   - 의미 완결성 (사람이 읽어서 이해 가능한가?)

3. 최적 전략 선택
   - 정량/정성 평가 결과 종합
   - Phase 5 학습 데이터 생성에 적용

---

## 결론

**Phase 1~2 완료**로 프로젝트의 **탄탄한 기반**을 마련했습니다. 특히 **4개 한국어 임베딩 모델에 대한 정량적 평가**와 **7가지 기준의 체계적 선정 프로세스**는 향후 다른 도메인 적응 프로젝트에도 재활용 가능한 방법론입니다.

**핵심 성과**:
1. 임베딩 모델 기초 이론 습득 및 베이스라인 실험 (Phase 1 완료)
2. 한국어 임베딩 모델 4개 정량 평가 및 `jhgan/ko-sroberta-multitask` 선정 (Phase 2 완료)
3. 모델 평가, 메트릭 이해, 트레이드오프 분석, 도메인 적응 **4대 핵심 문서** 작성 (Phase 2 완료)
4. 법령정보시스템 구조 분석 및 데이터 카탈로그 작성 (Phase 3 - 이슈 #5 완료, 12/3)

**현재 상태**:
- Phase 1~2 완료
- Phase 3 진행 중 (데이터 수집 방법 연구 및 파일럿 수집 - 이슈 #6, #7)

**다음 마일스톤**:
- Phase 3 완료 (데이터 수집 자동화)
- Phase 4 완료 (청킹 전략 선택 및 전처리 파이프라인)
- Phase 5 완료 (학습 데이터 100-500 pairs 생성)
- Phase 6 완료 (첫 파인튜닝 실험 및 결과 분석)

**예상 타임라인**:
- Phase 3~4: 2025년 12월 중 완료 목표
- Phase 5~6: 2026년 1월
- Phase 7~9: 2026년 1월~2월
- Phase 10: 2026년 3월 (최종 결과 공유)

---

**문서 작성일**: 2025년 12월 6일  
**연구 진행 상태**: Phase 1~2 완료, Phase 3 진행 중






